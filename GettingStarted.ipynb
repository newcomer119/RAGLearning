{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0062cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c87e326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile={'max_input_tokens': 16385, 'max_output_tokens': 4096, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': False, 'structured_output': False, 'image_url_inputs': False, 'pdf_inputs': False, 'pdf_tool_message': False, 'image_tool_message': False, 'tool_choice': True} client=<openai.resources.chat.completions.completions.Completions object at 0x000001FF67DE2920> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001FF67DE2B60> root_client=<openai.OpenAI object at 0x000001FF67DE28F0> root_async_client=<openai.AsyncOpenAI object at 0x000001FF67DE2740> model_kwargs={} openai_api_key=SecretStr('**********') stream_usage=True\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d59135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response from LLM\n",
    "result = llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65c643e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to algorithms and techniques that are designed to generate new and original content, such as images, text, or music, rather than just analyzing or processing existing data. Generative AI can be used to create realistic and convincing content that is not based on any specific input, making it a powerful tool for various applications such as creating art, generating new ideas, or enhancing creativity in various fields.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 13, 'total_tokens': 94, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-D6vfo381BAPQjrj1GLbCifh4l1rTo', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019c3ca5-f98c-7501-a315-c19849ce0ca3-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 13, 'output_tokens': 81, 'total_tokens': 94, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5642fa5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant that explains concepts in simple terms.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ChatPrompt Templates\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that explains concepts in simple terms.\"),\n",
    "    (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2de1bd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Of course! Langsmith is an AI deployment platform that helps users easily deploy and manage their AI models. It allows you to quickly deploy your trained models so they can be used in real-world applications. Langsmith provides tools and services to help you monitor the performance of your models, scale them as needed, and integrate them into your existing systems. It essentially streamlines the process of taking your AI models from development to deployment, making it easier for you to leverage the power of AI in your projects.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 36, 'total_tokens': 136, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-D6vnrUhn3tNKNR88QXxIvHkSIx1nD', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019c3cad-973b-7231-b2c8-024c371b066f-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 36, 'output_tokens': 100, 'total_tokens': 136, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "response = chain.invoke({\"input\": \"Can you tell me about Langsmith the ai deployement platform?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86b1a458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3d7d835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Langsmith is an AI deployment platform that allows users to easily deploy and manage their AI models. Users can upload their trained models to Langsmith, which then takes care of hosting, scaling, and serving the models through APIs. This makes it simple for businesses and developers to integrate AI capabilities into their applications without needing to worry about the infrastructure and deployment details. Langsmith helps streamline the process of deploying AI models, making it more accessible and efficient for users.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you tell me about Langsmith the ai deployement platform?\"})\n",
    "print(response)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
