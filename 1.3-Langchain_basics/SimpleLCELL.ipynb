{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "27105987",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os \n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import openai\n",
        "openai.api_key=os.getenv(\"OPENAI_API_KEY\")\n",
        "groqai_api_key=os.getenv(\"GROQ_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c0f7a2e3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 8192, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x0000022720026470>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000227202AE050>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_groq import ChatGroq\n",
        "# gemma2-9b-it was decommissioned; use a supported model (see https://console.groq.com/docs/models)\n",
        "model = ChatGroq(model=\"llama-3.1-8b-instant\", groq_api_key=groqai_api_key)\n",
        "model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "718957d6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The translation from English to French is:\\n\\nBonjour Comment ça va ? \\n\\n(Note: The more informal version would be: Salut Comment vas-tu ?)'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# Use a single user message (Groq Gemma can reject multi-role format)\n",
        "messages = [\n",
        "    HumanMessage(content=\"Translate the following from English to French: Hello How are you?\")\n",
        "]\n",
        "\n",
        "response = model.invoke(messages)\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9d62881c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The translation from English to French is:\\n\\nBonjour Comment ça va ? \\n\\n(Note: The more informal version would be: Salut Comment vas-tu ?)'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "parser = StrOutputParser()\n",
        "parser.invoke(response)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "cfa0e546",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "generic_template = \"Translate the following into {language}\"\n",
        "\n",
        "# Note the 's' in from_messages\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", generic_template),\n",
        "    (\"user\", \"{text}\")\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "c0d23698",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='Translate the following into French', additional_kwargs={}, response_metadata={}), HumanMessage(content='hello', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt.invoke({\"language\":\"French\",\"text\":\"hello\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "606c1660",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Bonjour.'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain=prompt | model | parser\n",
        "chain.invoke({\"language\":\"French\",\"text\":\"Hello\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a0a3091",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3175ac4d",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de83b079",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58776d78",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
